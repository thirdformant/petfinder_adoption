{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Petfinder.my competition: modelling, part one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and misc function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import feather\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_confmatrix(confusion_matrices:list, normalise:bool=True):\n",
    "    mean_confmatrix = confusion_matrix(y_train, np.round(np.mean(lgb_preds, axis=1)))\n",
    "    if normalise:\n",
    "        mean_confmatrix = mean_confmatrix.astype('float') / mean_confmatrix.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(mean_confmatrix, annot=True)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if normalise:\n",
    "        plt.title('Normalised confusion matrix')\n",
    "    else:\n",
    "        plt.title('Confusion matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = os.path.join(os.pardir, 'data', 'interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = feather.read_dataframe(os.path.join(INPUT_PATH, 'train.feather'))\n",
    "all_test = feather.read_dataframe(os.path.join(INPUT_PATH, 'test.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits the training data into training and validation data sets. The size of the validation data was calculated to match the size of the final unseen testing data relative to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_colnames = ['RescuerID', 'PetID', 'PrimaryLabel', 'SecondaryLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical data\n",
    "all_data = [all_train, all_test]\n",
    "\n",
    "for df in all_data:\n",
    "    for col in cat_colnames:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "        df[col] = df[col].cat.codes\n",
    "        df[col] = pd.Categorical(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Name', 'Description', 'AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_train.drop(drop_cols, axis=1)\n",
    "y_train = all_train['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, y_train, y_valid = train_test_split(training_data, training_labels,\n",
    "#                                                      test_size=len(all_test) / len(all_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 346) (14993,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM: classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits a LightGBM classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition uses the quadratic weighted kappa for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_metric(predictions, actuals):\n",
    "    \"\"\"\n",
    "    Competition scores are calculated with the quadratic weighted kappa.\n",
    "    The cohen_kappa_score from sklearn.metrics is identical\n",
    "    \"\"\"\n",
    "    return cohen_kappa_score(predictions, actuals, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 80,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 60,\n",
    "          'min_sum_hessian_in_leaf': 0.01,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_frequency': 2,\n",
    "          'feature_fraction': 0.75,\n",
    "          'lambda_l2': 0.05,\n",
    "          'min_gain_to_split': 0.0,\n",
    "          'max_bin': 255,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and CV functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(train_data, train_labels, valid_data, valid_labels,\n",
    "              model_params, scoring_metric, X_test=None):\n",
    "    \n",
    "    # Create training and validation lgb dataset objects\n",
    "    lgb_X_train = lgb.Dataset(data=train_data, label=train_labels,\n",
    "                              feature_name='auto', categorical_feature='auto',\n",
    "                              free_raw_data=False)\n",
    "    lgb_X_valid = lgb.Dataset(data=valid_data, label=valid_labels,\n",
    "                              feature_name='auto', categorical_feature='auto',\n",
    "                              free_raw_data=False)\n",
    "    \n",
    "    # Get parameters\n",
    "    params2 = model_params.copy()\n",
    "    num_iterations = params2.pop('num_iterations')\n",
    "    early_stopping = params2.pop('early_stopping_rounds')\n",
    "    verbose_eval = params2.pop('verbose_eval')\n",
    "    \n",
    "    # Train LightGBM model\n",
    "    print(\"Training the LightGBM model...\")\n",
    "    model = lgb.train(params2,\n",
    "                          lgb_X_train,\n",
    "                          num_boost_round=num_iterations,\n",
    "                          valid_sets=[lgb_X_train, lgb_X_valid],\n",
    "                          early_stopping_rounds=early_stopping,\n",
    "                          verbose_eval=verbose_eval)\n",
    "    \n",
    "    # Get model predictions on validation set\n",
    "    print(\"Fitting the model to the validation data...\")\n",
    "    y_probs = model.predict(valid_data, num_iteration=model.best_iteration,\n",
    "                           verbose_eval=verbose_eval) # Class probabilities from model\n",
    "    \n",
    "    \n",
    "    y_preds = np.apply_along_axis(np.argmax, 1, y_probs) # Get label value according to highest probability\n",
    "    qwk = scoring_metric(y_preds, valid_labels) # Compute kappa score\n",
    "    conf_matrix = confusion_matrix(valid_labels, y_preds)\n",
    "    importances = model.feature_importance() # Get feature importances\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Actual distribution of labels: {Counter(valid_labels)}\")\n",
    "    print(f\"Predicted distribution of labels: {Counter(y_preds)}\")\n",
    "    print(f\"CV split QWK score: {qwk}\")\n",
    "    print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return y_probs, y_preds, qwk, conf_matrix, importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(X:pd.DataFrame, y:list, nsplits:int, params):\n",
    "    fold_counter = 1 #The current fold number\n",
    "    skf = StratifiedKFold(n_splits=nsplits, shuffle=True)\n",
    "    \n",
    "    lgb_preds = np.zeros((X.shape[0], nsplits))\n",
    "    lgb_pred_probs = []\n",
    "    lgb_confusion_matrices = []\n",
    "    lgb_qwk_scores = []\n",
    "    feature_importances = pd.DataFrame()\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        print(f\"Fold {fold_counter} / {nsplits}:\")\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        # Fit model\n",
    "        y_probs, y_preds, qwk, conf_matrix, imps = lgb_model(X_train, y_train, X_valid, y_valid, params, kappa_metric)\n",
    "        \n",
    "        lgb_preds[valid_index] = y_preds.reshape(-1, 1)\n",
    "        lgb_pred_probs.append(y_probs)\n",
    "        lgb_qwk_scores.append(qwk)\n",
    "        lgb_confusion_matrices.append(conf_matrix)\n",
    "        \n",
    "        fold_importances = pd.DataFrame()\n",
    "        fold_importances['Features'] = X.columns.values\n",
    "        fold_importances['Importance'] = imps\n",
    "        fold_importances['FoldNum'] = fold_counter\n",
    "        feature_importances = pd.concat([feature_importances, fold_importances], axis=0)\n",
    "        fold_counter += 1\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"QWK scores: {lgb_qwk_scores}\")\n",
    "    print(f\"Mean QWK score: {np.mean(lgb_qwk_scores)}\")\n",
    "    print(f\"QWK score sd: {np.std(lgb_qwk_scores)}\")\n",
    "    return lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices, feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices = cv_model(X_train, y_train, 5, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22532\tvalid_1's multi_logloss: 1.35714\n",
      "[200]\ttraining's multi_logloss: 1.0636\tvalid_1's multi_logloss: 1.311\n",
      "[300]\ttraining's multi_logloss: 0.935603\tvalid_1's multi_logloss: 1.28653\n",
      "[400]\ttraining's multi_logloss: 0.829355\tvalid_1's multi_logloss: 1.27256\n",
      "[500]\ttraining's multi_logloss: 0.738832\tvalid_1's multi_logloss: 1.26488\n",
      "[600]\ttraining's multi_logloss: 0.660858\tvalid_1's multi_logloss: 1.26215\n",
      "[700]\ttraining's multi_logloss: 0.593001\tvalid_1's multi_logloss: 1.26061\n",
      "[800]\ttraining's multi_logloss: 0.53339\tvalid_1's multi_logloss: 1.26075\n",
      "Early stopping, best iteration is:\n",
      "[746]\ttraining's multi_logloss: 0.564723\tvalid_1's multi_logloss: 1.26041\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1208, 2: 768, 1: 567, 3: 446, 0: 11})\n",
      "CV split QWK score: 0.3910499044899528\n",
      "Confusion matrix:\n",
      " [[  7  21  19   7  28]\n",
      " [  2 228 189  60 139]\n",
      " [  2 152 307 148 199]\n",
      " [  0  94 166 190 202]\n",
      " [  0  72  87  41 640]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22415\tvalid_1's multi_logloss: 1.36173\n",
      "[200]\ttraining's multi_logloss: 1.06135\tvalid_1's multi_logloss: 1.31692\n",
      "[300]\ttraining's multi_logloss: 0.9338\tvalid_1's multi_logloss: 1.29405\n",
      "[400]\ttraining's multi_logloss: 0.827679\tvalid_1's multi_logloss: 1.27964\n",
      "[500]\ttraining's multi_logloss: 0.737323\tvalid_1's multi_logloss: 1.27286\n",
      "[600]\ttraining's multi_logloss: 0.659251\tvalid_1's multi_logloss: 1.2696\n",
      "[700]\ttraining's multi_logloss: 0.591286\tvalid_1's multi_logloss: 1.26832\n",
      "[800]\ttraining's multi_logloss: 0.531756\tvalid_1's multi_logloss: 1.2685\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's multi_logloss: 0.578102\tvalid_1's multi_logloss: 1.26792\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1246, 2: 807, 1: 545, 3: 393, 0: 9})\n",
      "CV split QWK score: 0.39248056736256254\n",
      "Confusion matrix:\n",
      " [[  6  23  19   7  27]\n",
      " [  3 225 185  49 156]\n",
      " [  0 147 333 120 208]\n",
      " [  0  93 175 174 210]\n",
      " [  0  57  95  43 645]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22261\tvalid_1's multi_logloss: 1.35818\n",
      "[200]\ttraining's multi_logloss: 1.05955\tvalid_1's multi_logloss: 1.31246\n",
      "[300]\ttraining's multi_logloss: 0.932022\tvalid_1's multi_logloss: 1.28759\n",
      "[400]\ttraining's multi_logloss: 0.826085\tvalid_1's multi_logloss: 1.2729\n",
      "[500]\ttraining's multi_logloss: 0.736067\tvalid_1's multi_logloss: 1.26542\n",
      "[600]\ttraining's multi_logloss: 0.658364\tvalid_1's multi_logloss: 1.26204\n",
      "[700]\ttraining's multi_logloss: 0.590793\tvalid_1's multi_logloss: 1.26045\n",
      "[800]\ttraining's multi_logloss: 0.531605\tvalid_1's multi_logloss: 1.26093\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's multi_logloss: 0.574692\tvalid_1's multi_logloss: 1.26024\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1224, 2: 816, 1: 582, 3: 367, 0: 9})\n",
      "CV split QWK score: 0.42264461952048893\n",
      "Confusion matrix:\n",
      " [[  5  21  24   9  23]\n",
      " [  3 239 199  46 131]\n",
      " [  1 179 303 119 205]\n",
      " [  0  80 203 159 210]\n",
      " [  0  63  87  34 655]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22424\tvalid_1's multi_logloss: 1.35801\n",
      "[200]\ttraining's multi_logloss: 1.06167\tvalid_1's multi_logloss: 1.31169\n",
      "[300]\ttraining's multi_logloss: 0.933778\tvalid_1's multi_logloss: 1.28695\n",
      "[400]\ttraining's multi_logloss: 0.827528\tvalid_1's multi_logloss: 1.27396\n",
      "[500]\ttraining's multi_logloss: 0.737286\tvalid_1's multi_logloss: 1.26741\n",
      "[600]\ttraining's multi_logloss: 0.659739\tvalid_1's multi_logloss: 1.26518\n",
      "[700]\ttraining's multi_logloss: 0.591976\tvalid_1's multi_logloss: 1.26437\n",
      "[800]\ttraining's multi_logloss: 0.532684\tvalid_1's multi_logloss: 1.26463\n",
      "Early stopping, best iteration is:\n",
      "[739]\ttraining's multi_logloss: 0.56797\tvalid_1's multi_logloss: 1.26396\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1245, 2: 814, 1: 524, 3: 410, 0: 5})\n",
      "CV split QWK score: 0.3757000805147891\n",
      "Confusion matrix:\n",
      " [[  3  24  23   3  29]\n",
      " [  1 220 180  60 157]\n",
      " [  0 140 313 130 224]\n",
      " [  1  83 200 183 185]\n",
      " [  0  57  98  34 650]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22501\tvalid_1's multi_logloss: 1.35942\n",
      "[200]\ttraining's multi_logloss: 1.0621\tvalid_1's multi_logloss: 1.31185\n",
      "[300]\ttraining's multi_logloss: 0.935496\tvalid_1's multi_logloss: 1.28605\n",
      "[400]\ttraining's multi_logloss: 0.829844\tvalid_1's multi_logloss: 1.27083\n",
      "[500]\ttraining's multi_logloss: 0.740177\tvalid_1's multi_logloss: 1.26142\n",
      "[600]\ttraining's multi_logloss: 0.662426\tvalid_1's multi_logloss: 1.25611\n",
      "[700]\ttraining's multi_logloss: 0.594692\tvalid_1's multi_logloss: 1.25276\n",
      "[800]\ttraining's multi_logloss: 0.535173\tvalid_1's multi_logloss: 1.25048\n",
      "[900]\ttraining's multi_logloss: 0.482619\tvalid_1's multi_logloss: 1.25019\n",
      "[1000]\ttraining's multi_logloss: 0.436272\tvalid_1's multi_logloss: 1.2519\n",
      "Early stopping, best iteration is:\n",
      "[917]\ttraining's multi_logloss: 0.474358\tvalid_1's multi_logloss: 1.25011\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1222, 2: 829, 1: 533, 3: 407, 0: 6})\n",
      "CV split QWK score: 0.41348693021865135\n",
      "Confusion matrix:\n",
      " [[  4  22  20   9  27]\n",
      " [  1 253 191  60 113]\n",
      " [  0 122 314 129 242]\n",
      " [  1  82 202 175 191]\n",
      " [  0  54 102  34 649]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "QWK scores: [0.3910499044899528, 0.39248056736256254, 0.42264461952048893, 0.3757000805147891, 0.41348693021865135]\n",
      "Mean QWK score: 0.39907242042128893\n",
      "QWK score sd: 0.016837495207969205\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 60,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 120,\n",
    "          'min_sum_hessian_in_leaf': 0.01,\n",
    "          'bagging_fraction': 0.8,\n",
    "          'bagging_frequency': 2,\n",
    "          'feature_fraction': 0.8,\n",
    "          'lambda_l2': 0.05,\n",
    "          'min_gain_to_split': 0.0,\n",
    "          'max_bin': 255,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }\n",
    "\n",
    "lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices, feature_importances = cv_model(X_train,\n",
    "                                                                                                  y_train, \n",
    "                                                                                                  5, \n",
    "                                                                                                  params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_importances = feature_importances.groupby('Features')[\"Features\", \"Importance\"].mean().reset_index()\\\n",
    "                                        .sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>642.215029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>390.971315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>619.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>677.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6729.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Importance\n",
       "count   346.000000\n",
       "mean    642.215029\n",
       "std     390.971315\n",
       "min       0.000000\n",
       "25%     563.000000\n",
       "50%     619.500000\n",
       "75%     677.400000\n",
       "max    6729.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = list(mean_importances['Features'][mean_importances['Importance'] < \n",
    "                                                       mean_importances['Importance'].median()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features which had importances below the median importance were dropped from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = X_train.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.25222\tvalid_1's multi_logloss: 1.37374\n",
      "[200]\ttraining's multi_logloss: 1.10097\tvalid_1's multi_logloss: 1.32661\n",
      "[300]\ttraining's multi_logloss: 0.982391\tvalid_1's multi_logloss: 1.30099\n",
      "[400]\ttraining's multi_logloss: 0.885237\tvalid_1's multi_logloss: 1.2863\n",
      "[500]\ttraining's multi_logloss: 0.8001\tvalid_1's multi_logloss: 1.2777\n",
      "[600]\ttraining's multi_logloss: 0.726176\tvalid_1's multi_logloss: 1.27058\n",
      "[700]\ttraining's multi_logloss: 0.66185\tvalid_1's multi_logloss: 1.26759\n",
      "[800]\ttraining's multi_logloss: 0.604327\tvalid_1's multi_logloss: 1.26582\n",
      "[900]\ttraining's multi_logloss: 0.552458\tvalid_1's multi_logloss: 1.2635\n",
      "Early stopping, best iteration is:\n",
      "[888]\ttraining's multi_logloss: 0.55826\tvalid_1's multi_logloss: 1.26334\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1194, 2: 881, 1: 521, 3: 400, 0: 4})\n",
      "CV split QWK score: 0.3902863243249728\n",
      "Confusion matrix:\n",
      " [[  3  26  21   5  27]\n",
      " [  1 221 196  49 151]\n",
      " [  0 138 339 128 203]\n",
      " [  0  88 212 176 176]\n",
      " [  0  48 113  42 637]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.25097\tvalid_1's multi_logloss: 1.36941\n",
      "[200]\ttraining's multi_logloss: 1.10133\tvalid_1's multi_logloss: 1.32147\n",
      "[300]\ttraining's multi_logloss: 0.98317\tvalid_1's multi_logloss: 1.29244\n",
      "[400]\ttraining's multi_logloss: 0.885584\tvalid_1's multi_logloss: 1.27494\n",
      "[500]\ttraining's multi_logloss: 0.800954\tvalid_1's multi_logloss: 1.26481\n",
      "[600]\ttraining's multi_logloss: 0.727765\tvalid_1's multi_logloss: 1.25729\n",
      "[700]\ttraining's multi_logloss: 0.663578\tvalid_1's multi_logloss: 1.25311\n",
      "[800]\ttraining's multi_logloss: 0.606187\tvalid_1's multi_logloss: 1.25103\n",
      "[900]\ttraining's multi_logloss: 0.554923\tvalid_1's multi_logloss: 1.2502\n",
      "[1000]\ttraining's multi_logloss: 0.509238\tvalid_1's multi_logloss: 1.24966\n",
      "Early stopping, best iteration is:\n",
      "[961]\ttraining's multi_logloss: 0.526184\tvalid_1's multi_logloss: 1.24938\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1172, 2: 911, 1: 505, 3: 400, 0: 12})\n",
      "CV split QWK score: 0.41505384970217196\n",
      "Confusion matrix:\n",
      " [[  7  25  20   7  23]\n",
      " [  2 237 200  58 121]\n",
      " [  1 118 360 113 216]\n",
      " [  1  76 206 182 187]\n",
      " [  1  49 125  40 625]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.25246\tvalid_1's multi_logloss: 1.37092\n",
      "[200]\ttraining's multi_logloss: 1.1028\tvalid_1's multi_logloss: 1.32616\n",
      "[300]\ttraining's multi_logloss: 0.985016\tvalid_1's multi_logloss: 1.29762\n",
      "[400]\ttraining's multi_logloss: 0.887036\tvalid_1's multi_logloss: 1.28232\n",
      "[500]\ttraining's multi_logloss: 0.802495\tvalid_1's multi_logloss: 1.27303\n",
      "[600]\ttraining's multi_logloss: 0.728974\tvalid_1's multi_logloss: 1.26551\n",
      "[700]\ttraining's multi_logloss: 0.664029\tvalid_1's multi_logloss: 1.2633\n",
      "[800]\ttraining's multi_logloss: 0.606686\tvalid_1's multi_logloss: 1.26101\n",
      "[900]\ttraining's multi_logloss: 0.555683\tvalid_1's multi_logloss: 1.25995\n",
      "[1000]\ttraining's multi_logloss: 0.509948\tvalid_1's multi_logloss: 1.26016\n",
      "Early stopping, best iteration is:\n",
      "[919]\ttraining's multi_logloss: 0.546405\tvalid_1's multi_logloss: 1.25961\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1179, 2: 867, 1: 554, 3: 394, 0: 4})\n",
      "CV split QWK score: 0.41808885658496253\n",
      "Confusion matrix:\n",
      " [[  4  25  24  11  18]\n",
      " [  0 233 196  56 133]\n",
      " [  0 151 340 113 203]\n",
      " [  0  90 214 166 182]\n",
      " [  0  55  93  48 643]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.25165\tvalid_1's multi_logloss: 1.38064\n",
      "[200]\ttraining's multi_logloss: 1.10159\tvalid_1's multi_logloss: 1.33685\n",
      "[300]\ttraining's multi_logloss: 0.982612\tvalid_1's multi_logloss: 1.31109\n",
      "[400]\ttraining's multi_logloss: 0.883797\tvalid_1's multi_logloss: 1.29444\n",
      "[500]\ttraining's multi_logloss: 0.798793\tvalid_1's multi_logloss: 1.28483\n",
      "[600]\ttraining's multi_logloss: 0.725577\tvalid_1's multi_logloss: 1.27892\n",
      "[700]\ttraining's multi_logloss: 0.660604\tvalid_1's multi_logloss: 1.2757\n",
      "[800]\ttraining's multi_logloss: 0.602897\tvalid_1's multi_logloss: 1.2744\n",
      "[900]\ttraining's multi_logloss: 0.55126\tvalid_1's multi_logloss: 1.27307\n",
      "Early stopping, best iteration is:\n",
      "[893]\ttraining's multi_logloss: 0.554618\tvalid_1's multi_logloss: 1.27282\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1246, 2: 759, 1: 580, 3: 411, 0: 2})\n",
      "CV split QWK score: 0.37826288070732506\n",
      "Confusion matrix:\n",
      " [[  2  24  17   8  31]\n",
      " [  0 243 167  69 139]\n",
      " [  0 154 290 122 241]\n",
      " [  0  99 190 182 181]\n",
      " [  0  60  95  30 654]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.25406\tvalid_1's multi_logloss: 1.37166\n",
      "[200]\ttraining's multi_logloss: 1.10361\tvalid_1's multi_logloss: 1.32411\n",
      "[300]\ttraining's multi_logloss: 0.985967\tvalid_1's multi_logloss: 1.29763\n",
      "[400]\ttraining's multi_logloss: 0.8861\tvalid_1's multi_logloss: 1.27884\n",
      "[500]\ttraining's multi_logloss: 0.801577\tvalid_1's multi_logloss: 1.26884\n",
      "[600]\ttraining's multi_logloss: 0.727789\tvalid_1's multi_logloss: 1.2631\n",
      "[700]\ttraining's multi_logloss: 0.663305\tvalid_1's multi_logloss: 1.26078\n",
      "[800]\ttraining's multi_logloss: 0.605805\tvalid_1's multi_logloss: 1.25948\n",
      "[900]\ttraining's multi_logloss: 0.554367\tvalid_1's multi_logloss: 1.25949\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's multi_logloss: 0.576975\tvalid_1's multi_logloss: 1.25881\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1221, 2: 832, 1: 563, 3: 374, 0: 7})\n",
      "CV split QWK score: 0.4021576878022465\n",
      "Confusion matrix:\n",
      " [[  5  23  21   3  30]\n",
      " [  1 241 198  51 127]\n",
      " [  0 151 324 111 221]\n",
      " [  1  81 188 174 207]\n",
      " [  0  67 101  35 636]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "QWK scores: [0.3902863243249728, 0.41505384970217196, 0.41808885658496253, 0.37826288070732506, 0.4021576878022465]\n",
      "Mean QWK score: 0.40076991982433585\n",
      "QWK score sd: 0.014982487828414605\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 60,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 80,\n",
    "          'min_sum_hessian_in_leaf': 0.05,\n",
    "          'bagging_fraction': 0.8,\n",
    "          'bagging_freq': 100,\n",
    "          'feature_fraction': 0.5,\n",
    "          'lambda_l2': 0.05,\n",
    "          'min_gain_to_split': 0.001,\n",
    "          'max_bin': 255,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }\n",
    "\n",
    "lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices, feature_importances = cv_model(X_train_reduced,\n",
    "                                                                                                  y_train, \n",
    "                                                                                                  5, \n",
    "                                                                                                  params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.23213\tvalid_1's multi_logloss: 1.36069\n",
      "[200]\ttraining's multi_logloss: 1.07674\tvalid_1's multi_logloss: 1.31424\n",
      "[300]\ttraining's multi_logloss: 0.955458\tvalid_1's multi_logloss: 1.29012\n",
      "[400]\ttraining's multi_logloss: 0.854997\tvalid_1's multi_logloss: 1.27479\n",
      "[500]\ttraining's multi_logloss: 0.769479\tvalid_1's multi_logloss: 1.26735\n",
      "[600]\ttraining's multi_logloss: 0.695062\tvalid_1's multi_logloss: 1.26214\n",
      "[700]\ttraining's multi_logloss: 0.630148\tvalid_1's multi_logloss: 1.25886\n",
      "[800]\ttraining's multi_logloss: 0.57195\tvalid_1's multi_logloss: 1.25729\n",
      "Early stopping, best iteration is:\n",
      "[793]\ttraining's multi_logloss: 0.575685\tvalid_1's multi_logloss: 1.2572\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1191, 2: 847, 1: 545, 3: 411, 0: 6})\n",
      "CV split QWK score: 0.40725498919537306\n",
      "Confusion matrix:\n",
      " [[  6  20  25   6  25]\n",
      " [  0 232 184  57 145]\n",
      " [  0 159 333 124 192]\n",
      " [  0  84 203 177 188]\n",
      " [  0  50 102  47 641]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.233\tvalid_1's multi_logloss: 1.36361\n",
      "[200]\ttraining's multi_logloss: 1.07829\tvalid_1's multi_logloss: 1.31693\n",
      "[300]\ttraining's multi_logloss: 0.957744\tvalid_1's multi_logloss: 1.29264\n",
      "[400]\ttraining's multi_logloss: 0.857718\tvalid_1's multi_logloss: 1.28017\n",
      "[500]\ttraining's multi_logloss: 0.772117\tvalid_1's multi_logloss: 1.27054\n",
      "[600]\ttraining's multi_logloss: 0.698309\tvalid_1's multi_logloss: 1.26558\n",
      "[700]\ttraining's multi_logloss: 0.633408\tvalid_1's multi_logloss: 1.26429\n",
      "[800]\ttraining's multi_logloss: 0.574998\tvalid_1's multi_logloss: 1.2635\n",
      "[900]\ttraining's multi_logloss: 0.523736\tvalid_1's multi_logloss: 1.26363\n",
      "Early stopping, best iteration is:\n",
      "[842]\ttraining's multi_logloss: 0.552338\tvalid_1's multi_logloss: 1.26294\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1208, 2: 823, 1: 554, 3: 409, 0: 6})\n",
      "CV split QWK score: 0.39462494225780853\n",
      "Confusion matrix:\n",
      " [[  3  22  26   5  26]\n",
      " [  1 236 180  62 139]\n",
      " [  1 150 327 124 206]\n",
      " [  1  81 193 176 201]\n",
      " [  0  65  97  42 636]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.23146\tvalid_1's multi_logloss: 1.35988\n",
      "[200]\ttraining's multi_logloss: 1.07651\tvalid_1's multi_logloss: 1.31162\n",
      "[300]\ttraining's multi_logloss: 0.954671\tvalid_1's multi_logloss: 1.28571\n",
      "[400]\ttraining's multi_logloss: 0.854606\tvalid_1's multi_logloss: 1.27305\n",
      "[500]\ttraining's multi_logloss: 0.769332\tvalid_1's multi_logloss: 1.2656\n",
      "[600]\ttraining's multi_logloss: 0.69475\tvalid_1's multi_logloss: 1.26325\n",
      "[700]\ttraining's multi_logloss: 0.62923\tvalid_1's multi_logloss: 1.26133\n",
      "[800]\ttraining's multi_logloss: 0.571058\tvalid_1's multi_logloss: 1.26112\n",
      "Early stopping, best iteration is:\n",
      "[736]\ttraining's multi_logloss: 0.606952\tvalid_1's multi_logloss: 1.26034\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1200, 2: 836, 1: 537, 3: 421, 0: 4})\n",
      "CV split QWK score: 0.39982818953045474\n",
      "Confusion matrix:\n",
      " [[  3  26  18  11  24]\n",
      " [  1 223 199  57 138]\n",
      " [  0 155 319 127 206]\n",
      " [  0  78 189 190 195]\n",
      " [  0  55 111  36 637]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.23317\tvalid_1's multi_logloss: 1.36187\n",
      "[200]\ttraining's multi_logloss: 1.07924\tvalid_1's multi_logloss: 1.31509\n",
      "[300]\ttraining's multi_logloss: 0.958701\tvalid_1's multi_logloss: 1.2891\n",
      "[400]\ttraining's multi_logloss: 0.856939\tvalid_1's multi_logloss: 1.27623\n",
      "[500]\ttraining's multi_logloss: 0.770512\tvalid_1's multi_logloss: 1.26594\n",
      "[600]\ttraining's multi_logloss: 0.695243\tvalid_1's multi_logloss: 1.26195\n",
      "[700]\ttraining's multi_logloss: 0.630161\tvalid_1's multi_logloss: 1.26073\n",
      "Early stopping, best iteration is:\n",
      "[684]\ttraining's multi_logloss: 0.639737\tvalid_1's multi_logloss: 1.26054\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1193, 2: 834, 1: 554, 3: 408, 0: 9})\n",
      "CV split QWK score: 0.3698221377344364\n",
      "Confusion matrix:\n",
      " [[  7  16  23   7  29]\n",
      " [  2 230 179  57 150]\n",
      " [  0 147 325 123 212]\n",
      " [  0 100 194 187 171]\n",
      " [  0  61 113  34 631]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.23371\tvalid_1's multi_logloss: 1.36258\n",
      "[200]\ttraining's multi_logloss: 1.07778\tvalid_1's multi_logloss: 1.31815\n",
      "[300]\ttraining's multi_logloss: 0.955232\tvalid_1's multi_logloss: 1.29346\n",
      "[400]\ttraining's multi_logloss: 0.854514\tvalid_1's multi_logloss: 1.27993\n",
      "[500]\ttraining's multi_logloss: 0.769329\tvalid_1's multi_logloss: 1.27309\n",
      "[600]\ttraining's multi_logloss: 0.69494\tvalid_1's multi_logloss: 1.27175\n",
      "[700]\ttraining's multi_logloss: 0.629381\tvalid_1's multi_logloss: 1.26988\n",
      "Early stopping, best iteration is:\n",
      "[677]\ttraining's multi_logloss: 0.643534\tvalid_1's multi_logloss: 1.26962\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1239, 2: 826, 1: 552, 3: 373, 0: 7})\n",
      "CV split QWK score: 0.38375012910251705\n",
      "Confusion matrix:\n",
      " [[  4  24  19   4  31]\n",
      " [  2 233 192  48 143]\n",
      " [  0 149 301 125 232]\n",
      " [  0  94 200 168 189]\n",
      " [  1  52 114  28 644]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "QWK scores: [0.40725498919537306, 0.39462494225780853, 0.39982818953045474, 0.3698221377344364, 0.38375012910251705]\n",
      "Mean QWK score: 0.391056077564118\n",
      "QWK score sd: 0.013087005503193905\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 60,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 80,\n",
    "          'min_sum_hessian_in_leaf': 0.05,\n",
    "          'bagging_fraction': 0.8,\n",
    "          'bagging_freq': 100,\n",
    "          'feature_fraction': 0.8,\n",
    "          'lambda_l2': 0.05,\n",
    "          'min_gain_to_split': 0.001,\n",
    "          'max_bin': 255,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }\n",
    "\n",
    "lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices, feature_importances = cv_model(X_train_reduced,\n",
    "                                                                                                  y_train, \n",
    "                                                                                                  5, \n",
    "                                                                                                  params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least insofar as concerns the Kaggle competition public leaderboard, the initial models perform somewhat poorly. The multi-logloss results for each fold suggest the model is overfitting, but attempts to resolve by e.g. decreasing the `num_leaves` and `max_bin` hyperparameters did not consistently improve the QWK score within folds, nor the mean QWK score. Reducing the number of features also had minimal impact on the QWK score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual distribution of categories: Counter({4: 4197, 2: 4037, 3: 3259, 1: 3090, 0: 410})\n",
      "Predicted distribution of categories: Counter({4.0: 6031, 2.0: 4166, 1.0: 2742, 3.0: 2022, 0.0: 32})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Actual distribution of categories: {Counter(y_train)}\")\n",
    "print(f\"Predicted distribution of categories: {Counter(np.round(np.mean(lgb_preds, axis=1)))}\")\n",
    "# For some reason they're are out of order. I have no idea why..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of hyperparameter values, the models made similar classification errors. In terms of classification label distributions (above), the final model still struggles to accurately predict 0s and has a clear tendency to overpredict 4s. The former is likely caused by a relative lack of training examples and few strong predictors of class 0 in the feature set as discussed in the EDA notebook.\n",
    "\n",
    "Below is the confusion matrix for all folds in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_average_confmatrix(lgb_confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting patterns here (the exact values will vary a little):\n",
    "- Only 5.6% of actual 0s are accurately classified. Of those that are misclassified, 33% are wrongly considered category 4, with the almost all the rest split evenly between 1 and 2.\n",
    "- 37% of 1s are correctly classified. However, 30% are misclassified as 2s and a further 26% as 4s.\n",
    "- 28% of 3s are correct, with 30% wrong classified as 2s and 29% as 4s.\n",
    "\n",
    "This suggests that some form of redistributing the classifications might improve the overall accuracy (and, more importantly, QWK score) of the model. Luckily, some Kaggle users with more knowledge/experience than me have already gone down this route. What follows in the next section is an implementation of what appears to currently be the most popular solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM: regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section I fitted a LightGBM classification model to the training data. This did not perform as well as hoped, seemingly regardless of hyperparameter values, with an average overall QWK score of between about 0.399 and 0.400."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
