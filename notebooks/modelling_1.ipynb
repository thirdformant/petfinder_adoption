{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Petfinder.my competition: modelling, part one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and misc function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import feather\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_confmatrix(model_results:dict, normalise:bool=True):\n",
    "    mean_confmatrix = confusion_matrix(y_train, np.round(np.mean(model_results['lgb_preds'], axis=1)))\n",
    "    if normalise:\n",
    "        mean_confmatrix = mean_confmatrix.astype('float') / mean_confmatrix.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(mean_confmatrix, annot=True)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if normalise:\n",
    "        plt.title('Normalised confusion matrix')\n",
    "    else:\n",
    "        plt.title('Confusion matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = os.path.join(os.pardir, 'data', 'interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = feather.read_dataframe(os.path.join(INPUT_PATH, 'train.feather'))\n",
    "all_test = feather.read_dataframe(os.path.join(INPUT_PATH, 'test.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits the training data into training and validation data sets. The size of the validation data was calculated to match the size of the final unseen testing data relative to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_colnames = ['RescuerID', 'PetID', 'PrimaryLabel', 'SecondaryLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical data\n",
    "all_data = [all_train, all_test]\n",
    "\n",
    "for df in all_data:\n",
    "    for col in cat_colnames:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "        df[col] = df[col].cat.codes\n",
    "        df[col] = pd.Categorical(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Name', 'Description', 'AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_train.drop(drop_cols, axis=1)\n",
    "y_train = all_train['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, y_train, y_valid = train_test_split(training_data, training_labels,\n",
    "#                                                      test_size=len(all_test) / len(all_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 346) (14993,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model scoring metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Competition submissions are evaluated in terms of the Quadratic Weighted Kappa (QWK; $\\kappa$) score. This is a measure of agreement between predicted and actual classification labels with respect to a baseline agreement in which labels are considered to be randomly allocated. In this regard it is a more robust metric than a simple measure of accuracy as it tries to account for situations in which agreement between predicted and actual labels has arisen by chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for calculating the QWK score is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\kappa = 1 - \\frac{\\sum_{ij}w_{ij}O_{ij}}{\\sum_{ij}w_{ij}E_{ij}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- $O_{ij}$ is an $N\\times N$ histogram matrix of observed values where $i$ is the actual label value and $j$ the predicted label. In other words, $O_{ij}$ equivalent to the confusion matrix.\n",
    "\n",
    "- $E_{ij}$ is a $N\\times N$ histogram matrix of the expected label values which assumes there is no correlation between the predicted and actual labels. This is the outer product between the histogram vectors of predicted and actual labels: $\\frac{\\sum_{i}O_{ij}\\otimes\\sum_{j}O_{ij}}{\\sum (\\sum_{i}O_{ij})}$ where $O_{ij}$ is the matrix of observed values.\n",
    "\n",
    "- $w_{ij}$ is the quadratic weights matrix calculated from the difference between actual and predicted labels: $w_{ij} = \\frac{(i - j)^2}{(N - 1)^2}$ where $i$ is the actual label value and $j$ the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[12 15 18] [ 6 15 24]\n",
      "[[1.6 4.  6.4]\n",
      " [2.  5.  8. ]\n",
      " [2.4 6.  9.6]]\n",
      "45\n",
      "45.0\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "Oij = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "sum_actual = np.sum(Oij, axis=0)\n",
    "sum_pred = np.sum(Oij, axis=1)\n",
    "print(Oij)\n",
    "print(sum_actual, sum_pred)\n",
    "Eij = np.outer(sum_actual, sum_pred) / np.sum(sum_pred)\n",
    "print(Eij)\n",
    "print(np.sum(Oij))\n",
    "print(np.sum(Eij))\n",
    "print(np.sum(sum_actual + sum_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QWK is a weighted variant of Cohen's kappa score which is implemented in the `metrics` module of scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_metric(predictions, actuals):\n",
    "    return cohen_kappa_score(predictions, actuals, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM: classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a classification problem, I initially fitted a LightGBM classification model to the data with 5-fold cross-validation. As the model uses a softmax function, the predicted classification label was that with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and CV functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(train_data, train_labels, valid_data, valid_labels,\n",
    "              model_params, scoring_metric, X_test=None):\n",
    "    \n",
    "    # Create training and validation lgb dataset objects\n",
    "    lgb_X_train = lgb.Dataset(data=train_data, label=train_labels,\n",
    "                              feature_name='auto', categorical_feature='auto',\n",
    "                              free_raw_data=False)\n",
    "    lgb_X_valid = lgb.Dataset(data=valid_data, label=valid_labels,\n",
    "                              feature_name='auto', categorical_feature='auto',\n",
    "                              free_raw_data=False)\n",
    "    \n",
    "    # Get parameters\n",
    "    params2 = model_params.copy()\n",
    "    num_iterations = params2.pop('num_iterations')\n",
    "    early_stopping = params2.pop('early_stopping_rounds')\n",
    "    verbose_eval = params2.pop('verbose_eval')\n",
    "    \n",
    "    # Train LightGBM model\n",
    "    print(\"Training the LightGBM model...\")\n",
    "    model = lgb.train(params2,\n",
    "                          lgb_X_train,\n",
    "                          num_boost_round=num_iterations,\n",
    "                          valid_sets=[lgb_X_train, lgb_X_valid],\n",
    "                          early_stopping_rounds=early_stopping,\n",
    "                          verbose_eval=verbose_eval)\n",
    "    \n",
    "    # Get model predictions on validation set\n",
    "    print(\"Fitting the model to the validation data...\")\n",
    "    y_probs = model.predict(valid_data, num_iteration=model.best_iteration,\n",
    "                           verbose_eval=verbose_eval) # Class probabilities from model\n",
    "    \n",
    "    \n",
    "    y_preds = np.apply_along_axis(np.argmax, 1, y_probs) # Get label value according to highest probability\n",
    "    qwk = scoring_metric(y_preds, valid_labels) # Compute kappa score\n",
    "    conf_matrix = confusion_matrix(valid_labels, y_preds)\n",
    "    importances = model.feature_importance() # Get feature importances\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Actual distribution of labels: {Counter(valid_labels)}\")\n",
    "    print(f\"Predicted distribution of labels: {Counter(y_preds)}\")\n",
    "    print(f\"CV split QWK score: {qwk}\")\n",
    "    print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return y_probs, y_preds, qwk, conf_matrix, importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(X:pd.DataFrame, y:list, nsplits:int, params):\n",
    "    fold_counter = 1 #The current fold number\n",
    "    skf = StratifiedKFold(n_splits=nsplits, shuffle=True)\n",
    "    \n",
    "    results = {\n",
    "        \"lgb_preds\": np.zeros((X.shape[0], nsplits)),\n",
    "        \"lgb_pred_probs\": [],\n",
    "        \"lgb_confusion_matrices\": [],\n",
    "        \"lgb_qwk_scores\": [],\n",
    "        \"feature_importances\": pd.DataFrame()\n",
    "    }\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        print(f\"Fold {fold_counter} / {nsplits}:\")\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        # Fit model\n",
    "        y_probs, y_preds, qwk, conf_matrix, imps = lgb_model(X_train, y_train, X_valid, y_valid, params, kappa_metric)\n",
    "        \n",
    "        results[\"lgb_preds\"][valid_index] = y_preds.reshape(-1, 1)\n",
    "        results[\"lgb_pred_probs\"].append(y_probs)\n",
    "        results[\"lgb_qwk_scores\"].append(qwk)\n",
    "        results[\"lgb_confusion_matrices\"].append(conf_matrix)\n",
    "        \n",
    "        fold_importances = pd.DataFrame()\n",
    "        fold_importances['Features'] = X.columns.values\n",
    "        fold_importances['Importance'] = imps\n",
    "        fold_importances['FoldNum'] = fold_counter\n",
    "        results[\"feature_importances\"] = pd.concat([results[\"feature_importances\"], fold_importances], axis=0)\n",
    "        fold_counter += 1\n",
    "\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"QWK scores: {results['lgb_qwk_scores']}\")\n",
    "    print(f\"Mean QWK score: {np.mean(results['lgb_qwk_scores'])}\")\n",
    "    print(f\"QWK score sd: {np.std(results['lgb_qwk_scores'])}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some experimentation, the hyperparameters below appear to produce the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.32499\tvalid_1's multi_logloss: 1.38171\n",
      "[200]\ttraining's multi_logloss: 1.23381\tvalid_1's multi_logloss: 1.33923\n",
      "[300]\ttraining's multi_logloss: 1.16563\tvalid_1's multi_logloss: 1.31601\n",
      "[400]\ttraining's multi_logloss: 1.1089\tvalid_1's multi_logloss: 1.30088\n",
      "[500]\ttraining's multi_logloss: 1.06036\tvalid_1's multi_logloss: 1.29114\n",
      "[600]\ttraining's multi_logloss: 1.017\tvalid_1's multi_logloss: 1.28478\n",
      "[700]\ttraining's multi_logloss: 0.978017\tvalid_1's multi_logloss: 1.28029\n",
      "[800]\ttraining's multi_logloss: 0.941977\tvalid_1's multi_logloss: 1.27719\n",
      "[900]\ttraining's multi_logloss: 0.908157\tvalid_1's multi_logloss: 1.27498\n",
      "[1000]\ttraining's multi_logloss: 0.876705\tvalid_1's multi_logloss: 1.27321\n",
      "[1100]\ttraining's multi_logloss: 0.847157\tvalid_1's multi_logloss: 1.27222\n",
      "[1200]\ttraining's multi_logloss: 0.819362\tvalid_1's multi_logloss: 1.27152\n",
      "[1300]\ttraining's multi_logloss: 0.792976\tvalid_1's multi_logloss: 1.27133\n",
      "[1400]\ttraining's multi_logloss: 0.767765\tvalid_1's multi_logloss: 1.27137\n",
      "Early stopping, best iteration is:\n",
      "[1322]\ttraining's multi_logloss: 0.787347\tvalid_1's multi_logloss: 1.27114\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1267, 2: 730, 1: 588, 3: 406, 0: 9})\n",
      "CV split QWK score: 0.39867194188010446\n",
      "Confusion matrix:\n",
      " [[  6  29  16   6  25]\n",
      " [  2 230 183  56 147]\n",
      " [  0 175 277 117 239]\n",
      " [  1  94 174 179 204]\n",
      " [  0  60  80  48 652]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.32601\tvalid_1's multi_logloss: 1.37927\n",
      "[200]\ttraining's multi_logloss: 1.2355\tvalid_1's multi_logloss: 1.33516\n",
      "[300]\ttraining's multi_logloss: 1.16781\tvalid_1's multi_logloss: 1.30961\n",
      "[400]\ttraining's multi_logloss: 1.11158\tvalid_1's multi_logloss: 1.29274\n",
      "[500]\ttraining's multi_logloss: 1.06298\tvalid_1's multi_logloss: 1.28178\n",
      "[600]\ttraining's multi_logloss: 1.0196\tvalid_1's multi_logloss: 1.27401\n",
      "[700]\ttraining's multi_logloss: 0.980381\tvalid_1's multi_logloss: 1.26871\n",
      "[800]\ttraining's multi_logloss: 0.944288\tvalid_1's multi_logloss: 1.2648\n",
      "[900]\ttraining's multi_logloss: 0.910554\tvalid_1's multi_logloss: 1.26173\n",
      "[1000]\ttraining's multi_logloss: 0.879338\tvalid_1's multi_logloss: 1.25946\n",
      "[1100]\ttraining's multi_logloss: 0.849847\tvalid_1's multi_logloss: 1.25799\n",
      "[1200]\ttraining's multi_logloss: 0.821886\tvalid_1's multi_logloss: 1.25744\n",
      "[1300]\ttraining's multi_logloss: 0.79537\tvalid_1's multi_logloss: 1.25699\n",
      "[1400]\ttraining's multi_logloss: 0.77014\tvalid_1's multi_logloss: 1.25704\n",
      "Early stopping, best iteration is:\n",
      "[1362]\ttraining's multi_logloss: 0.779588\tvalid_1's multi_logloss: 1.25673\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1177, 2: 839, 1: 601, 3: 377, 0: 6})\n",
      "CV split QWK score: 0.3954760950067223\n",
      "Confusion matrix:\n",
      " [[  2  26  21   6  27]\n",
      " [  2 249 191  40 136]\n",
      " [  0 156 322 121 209]\n",
      " [  2 101 204 183 162]\n",
      " [  0  69 101  27 643]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.32688\tvalid_1's multi_logloss: 1.3774\n",
      "[200]\ttraining's multi_logloss: 1.23657\tvalid_1's multi_logloss: 1.33215\n",
      "[300]\ttraining's multi_logloss: 1.16925\tvalid_1's multi_logloss: 1.30746\n",
      "[400]\ttraining's multi_logloss: 1.11266\tvalid_1's multi_logloss: 1.29098\n",
      "[500]\ttraining's multi_logloss: 1.06415\tvalid_1's multi_logloss: 1.28086\n",
      "[600]\ttraining's multi_logloss: 1.02102\tvalid_1's multi_logloss: 1.27346\n",
      "[700]\ttraining's multi_logloss: 0.982041\tvalid_1's multi_logloss: 1.26842\n",
      "[800]\ttraining's multi_logloss: 0.945975\tvalid_1's multi_logloss: 1.2651\n",
      "[900]\ttraining's multi_logloss: 0.912165\tvalid_1's multi_logloss: 1.26283\n",
      "[1000]\ttraining's multi_logloss: 0.880782\tvalid_1's multi_logloss: 1.2617\n",
      "[1100]\ttraining's multi_logloss: 0.851373\tvalid_1's multi_logloss: 1.26062\n",
      "[1200]\ttraining's multi_logloss: 0.823529\tvalid_1's multi_logloss: 1.26001\n",
      "[1300]\ttraining's multi_logloss: 0.796982\tvalid_1's multi_logloss: 1.25935\n",
      "[1400]\ttraining's multi_logloss: 0.7719\tvalid_1's multi_logloss: 1.25908\n",
      "[1500]\ttraining's multi_logloss: 0.747872\tvalid_1's multi_logloss: 1.25917\n",
      "Early stopping, best iteration is:\n",
      "[1463]\ttraining's multi_logloss: 0.756594\tvalid_1's multi_logloss: 1.25896\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1205, 2: 811, 1: 574, 3: 401, 0: 7})\n",
      "CV split QWK score: 0.397382502830255\n",
      "Confusion matrix:\n",
      " [[  7  23  18   5  29]\n",
      " [  0 235 193  60 130]\n",
      " [  0 160 320 109 218]\n",
      " [  0  92 180 184 196]\n",
      " [  0  64 100  43 632]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.32686\tvalid_1's multi_logloss: 1.37779\n",
      "[200]\ttraining's multi_logloss: 1.2368\tvalid_1's multi_logloss: 1.33291\n",
      "[300]\ttraining's multi_logloss: 1.16925\tvalid_1's multi_logloss: 1.30799\n",
      "[400]\ttraining's multi_logloss: 1.11248\tvalid_1's multi_logloss: 1.29177\n",
      "[500]\ttraining's multi_logloss: 1.06394\tvalid_1's multi_logloss: 1.28183\n",
      "[600]\ttraining's multi_logloss: 1.02045\tvalid_1's multi_logloss: 1.27583\n",
      "[700]\ttraining's multi_logloss: 0.981115\tvalid_1's multi_logloss: 1.2711\n",
      "[800]\ttraining's multi_logloss: 0.944865\tvalid_1's multi_logloss: 1.2682\n",
      "[900]\ttraining's multi_logloss: 0.911276\tvalid_1's multi_logloss: 1.26585\n",
      "[1000]\ttraining's multi_logloss: 0.879794\tvalid_1's multi_logloss: 1.2641\n",
      "[1100]\ttraining's multi_logloss: 0.850222\tvalid_1's multi_logloss: 1.26333\n",
      "[1200]\ttraining's multi_logloss: 0.822065\tvalid_1's multi_logloss: 1.26293\n",
      "[1300]\ttraining's multi_logloss: 0.795689\tvalid_1's multi_logloss: 1.26216\n",
      "[1400]\ttraining's multi_logloss: 0.77045\tvalid_1's multi_logloss: 1.26203\n",
      "Early stopping, best iteration is:\n",
      "[1389]\ttraining's multi_logloss: 0.7731\tvalid_1's multi_logloss: 1.26193\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1249, 2: 761, 1: 566, 3: 411, 0: 11})\n",
      "CV split QWK score: 0.4020384635943127\n",
      "Confusion matrix:\n",
      " [[  7  23  18   6  28]\n",
      " [  2 238 197  44 137]\n",
      " [  2 138 292 139 236]\n",
      " [  0 110 168 184 190]\n",
      " [  0  57  86  38 658]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.32434\tvalid_1's multi_logloss: 1.38375\n",
      "[200]\ttraining's multi_logloss: 1.23358\tvalid_1's multi_logloss: 1.34304\n",
      "[300]\ttraining's multi_logloss: 1.16574\tvalid_1's multi_logloss: 1.31952\n",
      "[400]\ttraining's multi_logloss: 1.10929\tvalid_1's multi_logloss: 1.30384\n",
      "[500]\ttraining's multi_logloss: 1.06085\tvalid_1's multi_logloss: 1.29374\n",
      "[600]\ttraining's multi_logloss: 1.01755\tvalid_1's multi_logloss: 1.28613\n",
      "[700]\ttraining's multi_logloss: 0.978376\tvalid_1's multi_logloss: 1.28051\n",
      "[800]\ttraining's multi_logloss: 0.942356\tvalid_1's multi_logloss: 1.27639\n",
      "[900]\ttraining's multi_logloss: 0.908896\tvalid_1's multi_logloss: 1.27322\n",
      "[1000]\ttraining's multi_logloss: 0.877671\tvalid_1's multi_logloss: 1.27093\n",
      "[1100]\ttraining's multi_logloss: 0.848292\tvalid_1's multi_logloss: 1.26929\n",
      "[1200]\ttraining's multi_logloss: 0.820614\tvalid_1's multi_logloss: 1.26792\n",
      "[1300]\ttraining's multi_logloss: 0.794285\tvalid_1's multi_logloss: 1.26704\n",
      "[1400]\ttraining's multi_logloss: 0.769347\tvalid_1's multi_logloss: 1.26662\n",
      "[1500]\ttraining's multi_logloss: 0.745691\tvalid_1's multi_logloss: 1.26627\n",
      "Early stopping, best iteration is:\n",
      "[1493]\ttraining's multi_logloss: 0.74733\tvalid_1's multi_logloss: 1.26616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1202, 2: 822, 1: 551, 3: 413, 0: 9})\n",
      "CV split QWK score: 0.39136815559980154\n",
      "Confusion matrix:\n",
      " [[  8  22  21   8  23]\n",
      " [  1 232 179  65 141]\n",
      " [  0 150 307 133 217]\n",
      " [  0  98 200 161 192]\n",
      " [  0  49 115  46 629]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "QWK scores: [0.39867194188010446, 0.3954760950067223, 0.397382502830255, 0.4020384635943127, 0.39136815559980154]\n",
      "Mean QWK score: 0.3969874317822392\n",
      "QWK score sd: 0.003531769568726421\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 20,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 120,\n",
    "          'min_sum_hessian_in_leaf': 0.01,\n",
    "          'bagging_fraction': 0.5,\n",
    "          'bagging_frequency': 100,\n",
    "          'feature_fraction': 0.5,\n",
    "          'lambda_l2': 0.01,\n",
    "          'min_gain_to_split': 0.0,\n",
    "          'max_bin': 100,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }\n",
    "\n",
    "classification_model1_results = cv_model(X_train, y_train, 5, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitting somewhat, even after altering the hyperparameters (as outlined in the [LightGBM docs](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)) to try to reduce this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many other situations, a reduction in the dimensionality of a random forest model by removing less important features has been found to improve the overall accuracy of the model. Here, features with a mean importance score lower than the median importance were dropped from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_importances = classification_model1_results['feature_importances'].groupby('Features')[\"Features\", \"Importance\"]\\\n",
    "                                        .mean().reset_index()\\\n",
    "                                        .sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RescuerID</td>\n",
       "      <td>7453.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>1805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Breed1</td>\n",
       "      <td>1631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PrimaryLabelScore</td>\n",
       "      <td>1158.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PhotoAmt</td>\n",
       "      <td>1112.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SecondaryLabelScore</td>\n",
       "      <td>941.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SecondaryLabel</td>\n",
       "      <td>915.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CropBoxArea</td>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TopRightY</td>\n",
       "      <td>763.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sterilized</td>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Quantity</td>\n",
       "      <td>614.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>svd_0</td>\n",
       "      <td>578.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>svd_258</td>\n",
       "      <td>569.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>svd_234</td>\n",
       "      <td>556.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>svd_284</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FurLength</td>\n",
       "      <td>555.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>svd_8</td>\n",
       "      <td>537.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>svd_44</td>\n",
       "      <td>536.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>svd_19</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DescWords</td>\n",
       "      <td>509.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>svd_9</td>\n",
       "      <td>509.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>svd_18</td>\n",
       "      <td>501.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breed2</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SentMagnitude</td>\n",
       "      <td>495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>svd_28</td>\n",
       "      <td>487.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TopRightX</td>\n",
       "      <td>487.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>svd_292</td>\n",
       "      <td>486.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PrimaryColorScore</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>svd_147</td>\n",
       "      <td>485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>svd_281</td>\n",
       "      <td>483.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>svd_98</td>\n",
       "      <td>251.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SecondaryBlue</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>svd_225</td>\n",
       "      <td>250.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>svd_287</td>\n",
       "      <td>249.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>svd_288</td>\n",
       "      <td>246.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>svd_54</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>svd_138</td>\n",
       "      <td>244.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>svd_149</td>\n",
       "      <td>241.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>svd_211</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>svd_226</td>\n",
       "      <td>233.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>svd_188</td>\n",
       "      <td>232.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>svd_177</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SecondaryGreen</td>\n",
       "      <td>226.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vaccinated</td>\n",
       "      <td>185.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>State</td>\n",
       "      <td>181.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SentScore</td>\n",
       "      <td>180.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PrimaryLabel</td>\n",
       "      <td>174.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fee</td>\n",
       "      <td>159.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Color2</td>\n",
       "      <td>129.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dewormed</td>\n",
       "      <td>118.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CropImportFrac</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Color3</td>\n",
       "      <td>50.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>VideoAmt</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IsNamed</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Type</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Health</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BottomLeftX</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HasDescription</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PetID</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BottomLeftY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Features  Importance\n",
       "29             RescuerID      7453.2\n",
       "0                    Age      1805.0\n",
       "3                 Breed1      1631.0\n",
       "26     PrimaryLabelScore      1158.2\n",
       "20              PhotoAmt      1112.4\n",
       "35   SecondaryLabelScore       941.4\n",
       "34        SecondaryLabel       915.6\n",
       "8            CropBoxArea       885.0\n",
       "42             TopRightY       763.4\n",
       "40            Sterilized       682.0\n",
       "28              Quantity       614.2\n",
       "46                 svd_0       578.2\n",
       "223              svd_258       569.6\n",
       "197              svd_234       556.6\n",
       "252              svd_284       556.0\n",
       "13             FurLength       555.2\n",
       "324                svd_8       537.6\n",
       "285               svd_44       536.6\n",
       "147               svd_19       510.0\n",
       "10             DescWords       509.8\n",
       "335                svd_9       509.2\n",
       "136               svd_18       501.6\n",
       "4                 Breed2       497.0\n",
       "37         SentMagnitude       495.0\n",
       "247               svd_28       487.8\n",
       "41             TopRightX       487.6\n",
       "261              svd_292       486.4\n",
       "23     PrimaryColorScore       486.0\n",
       "100              svd_147       485.0\n",
       "249              svd_281       483.6\n",
       "..                   ...         ...\n",
       "344               svd_98       251.6\n",
       "30         SecondaryBlue       251.0\n",
       "187              svd_225       250.2\n",
       "255              svd_287       249.8\n",
       "256              svd_288       246.4\n",
       "296               svd_54       245.0\n",
       "90               svd_138       244.2\n",
       "102              svd_149       241.8\n",
       "172              svd_211       237.0\n",
       "188              svd_226       233.8\n",
       "145              svd_188       232.4\n",
       "133              svd_177       231.0\n",
       "33        SecondaryGreen       226.8\n",
       "44            Vaccinated       185.8\n",
       "39                 State       181.8\n",
       "38             SentScore       180.4\n",
       "25          PrimaryLabel       174.8\n",
       "12                   Fee       159.6\n",
       "6                 Color2       129.8\n",
       "11              Dewormed       118.4\n",
       "9         CropImportFrac        63.2\n",
       "7                 Color3        50.4\n",
       "45              VideoAmt        39.8\n",
       "17               IsNamed        23.0\n",
       "43                  Type        21.4\n",
       "16                Health        10.0\n",
       "1            BottomLeftX         0.8\n",
       "15        HasDescription         0.0\n",
       "19                 PetID         0.0\n",
       "2            BottomLeftY         0.0\n",
       "\n",
       "[346 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>385.985549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>414.384151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>300.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>353.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>406.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7453.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Importance\n",
       "count   346.000000\n",
       "mean    385.985549\n",
       "std     414.384151\n",
       "min       0.000000\n",
       "25%     300.800000\n",
       "50%     353.200000\n",
       "75%     406.900000\n",
       "max    7453.200000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_importances.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = list(mean_importances['Features'][mean_importances['Importance'] < \n",
    "                                                       mean_importances['Importance'].median()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features which had importances below the median importance were dropped from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = X_train.drop(drop_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the lower dimension model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.31334\tvalid_1's multi_logloss: 1.37301\n",
      "[200]\ttraining's multi_logloss: 1.20803\tvalid_1's multi_logloss: 1.32322\n",
      "[300]\ttraining's multi_logloss: 1.12533\tvalid_1's multi_logloss: 1.29416\n",
      "[400]\ttraining's multi_logloss: 1.05562\tvalid_1's multi_logloss: 1.27477\n",
      "[500]\ttraining's multi_logloss: 0.993764\tvalid_1's multi_logloss: 1.26147\n",
      "[600]\ttraining's multi_logloss: 0.938158\tvalid_1's multi_logloss: 1.25249\n",
      "[700]\ttraining's multi_logloss: 0.887271\tvalid_1's multi_logloss: 1.24585\n",
      "[800]\ttraining's multi_logloss: 0.840571\tvalid_1's multi_logloss: 1.24104\n",
      "[900]\ttraining's multi_logloss: 0.797584\tvalid_1's multi_logloss: 1.23781\n",
      "[1000]\ttraining's multi_logloss: 0.757445\tvalid_1's multi_logloss: 1.23536\n",
      "[1100]\ttraining's multi_logloss: 0.720119\tvalid_1's multi_logloss: 1.23373\n",
      "[1200]\ttraining's multi_logloss: 0.685024\tvalid_1's multi_logloss: 1.23293\n",
      "[1300]\ttraining's multi_logloss: 0.652251\tvalid_1's multi_logloss: 1.23277\n",
      "[1400]\ttraining's multi_logloss: 0.621354\tvalid_1's multi_logloss: 1.23264\n",
      "Early stopping, best iteration is:\n",
      "[1341]\ttraining's multi_logloss: 0.639332\tvalid_1's multi_logloss: 1.23229\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1142, 2: 788, 1: 618, 3: 446, 0: 6})\n",
      "CV split QWK score: 0.42965419232591184\n",
      "Confusion matrix:\n",
      " [[  5  31  19   5  22]\n",
      " [  0 247 195  56 120]\n",
      " [  0 174 304 126 204]\n",
      " [  1 110 177 214 150]\n",
      " [  0  56  93  45 646]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.31221\tvalid_1's multi_logloss: 1.37692\n",
      "[200]\ttraining's multi_logloss: 1.20592\tvalid_1's multi_logloss: 1.3311\n",
      "[300]\ttraining's multi_logloss: 1.12249\tvalid_1's multi_logloss: 1.30418\n",
      "[400]\ttraining's multi_logloss: 1.05201\tvalid_1's multi_logloss: 1.28756\n",
      "[500]\ttraining's multi_logloss: 0.989398\tvalid_1's multi_logloss: 1.27592\n",
      "[600]\ttraining's multi_logloss: 0.933657\tvalid_1's multi_logloss: 1.26781\n",
      "[700]\ttraining's multi_logloss: 0.882733\tvalid_1's multi_logloss: 1.26162\n",
      "[800]\ttraining's multi_logloss: 0.836082\tvalid_1's multi_logloss: 1.25798\n",
      "[900]\ttraining's multi_logloss: 0.793293\tvalid_1's multi_logloss: 1.25487\n",
      "[1000]\ttraining's multi_logloss: 0.753249\tvalid_1's multi_logloss: 1.25309\n",
      "[1100]\ttraining's multi_logloss: 0.716024\tvalid_1's multi_logloss: 1.25205\n",
      "[1200]\ttraining's multi_logloss: 0.681088\tvalid_1's multi_logloss: 1.25156\n",
      "[1300]\ttraining's multi_logloss: 0.64857\tvalid_1's multi_logloss: 1.25151\n",
      "Early stopping, best iteration is:\n",
      "[1225]\ttraining's multi_logloss: 0.672842\tvalid_1's multi_logloss: 1.25145\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1212, 2: 819, 1: 543, 3: 415, 0: 11})\n",
      "CV split QWK score: 0.3967983731763258\n",
      "Confusion matrix:\n",
      " [[  6  24  19   3  30]\n",
      " [  2 245 176  57 138]\n",
      " [  2 126 336 132 212]\n",
      " [  1  92 179 183 197]\n",
      " [  0  56 109  40 635]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.31358\tvalid_1's multi_logloss: 1.37421\n",
      "[200]\ttraining's multi_logloss: 1.20787\tvalid_1's multi_logloss: 1.32518\n",
      "[300]\ttraining's multi_logloss: 1.125\tvalid_1's multi_logloss: 1.29602\n",
      "[400]\ttraining's multi_logloss: 1.05463\tvalid_1's multi_logloss: 1.27811\n",
      "[500]\ttraining's multi_logloss: 0.992489\tvalid_1's multi_logloss: 1.26628\n",
      "[600]\ttraining's multi_logloss: 0.936733\tvalid_1's multi_logloss: 1.25759\n",
      "[700]\ttraining's multi_logloss: 0.885989\tvalid_1's multi_logloss: 1.25143\n",
      "[800]\ttraining's multi_logloss: 0.83911\tvalid_1's multi_logloss: 1.24632\n",
      "[900]\ttraining's multi_logloss: 0.795771\tvalid_1's multi_logloss: 1.24346\n",
      "[1000]\ttraining's multi_logloss: 0.755906\tvalid_1's multi_logloss: 1.24136\n",
      "[1100]\ttraining's multi_logloss: 0.718442\tvalid_1's multi_logloss: 1.23998\n",
      "[1200]\ttraining's multi_logloss: 0.683407\tvalid_1's multi_logloss: 1.2389\n",
      "[1300]\ttraining's multi_logloss: 0.650452\tvalid_1's multi_logloss: 1.23832\n",
      "[1400]\ttraining's multi_logloss: 0.61949\tvalid_1's multi_logloss: 1.23839\n",
      "[1500]\ttraining's multi_logloss: 0.590232\tvalid_1's multi_logloss: 1.23869\n",
      "Early stopping, best iteration is:\n",
      "[1432]\ttraining's multi_logloss: 0.609935\tvalid_1's multi_logloss: 1.23816\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1154, 2: 827, 1: 583, 3: 423, 0: 11})\n",
      "CV split QWK score: 0.4254854877112828\n",
      "Confusion matrix:\n",
      " [[  6  27  17  10  22]\n",
      " [  3 244 189  56 126]\n",
      " [  1 162 339 113 192]\n",
      " [  0  89 189 197 177]\n",
      " [  1  61  93  47 637]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.31001\tvalid_1's multi_logloss: 1.38183\n",
      "[200]\ttraining's multi_logloss: 1.20262\tvalid_1's multi_logloss: 1.33874\n",
      "[300]\ttraining's multi_logloss: 1.11879\tvalid_1's multi_logloss: 1.31586\n",
      "[400]\ttraining's multi_logloss: 1.04761\tvalid_1's multi_logloss: 1.30124\n",
      "[500]\ttraining's multi_logloss: 0.985216\tvalid_1's multi_logloss: 1.29219\n",
      "[600]\ttraining's multi_logloss: 0.929473\tvalid_1's multi_logloss: 1.28605\n",
      "[700]\ttraining's multi_logloss: 0.87872\tvalid_1's multi_logloss: 1.28155\n",
      "[800]\ttraining's multi_logloss: 0.832039\tvalid_1's multi_logloss: 1.27871\n",
      "[900]\ttraining's multi_logloss: 0.788839\tvalid_1's multi_logloss: 1.27688\n",
      "[1000]\ttraining's multi_logloss: 0.748736\tvalid_1's multi_logloss: 1.2764\n",
      "[1100]\ttraining's multi_logloss: 0.71149\tvalid_1's multi_logloss: 1.2764\n",
      "Early stopping, best iteration is:\n",
      "[1015]\ttraining's multi_logloss: 0.742969\tvalid_1's multi_logloss: 1.27625\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1233, 2: 810, 1: 542, 3: 408, 0: 5})\n",
      "CV split QWK score: 0.41192448303799256\n",
      "Confusion matrix:\n",
      " [[  5  26  19   6  26]\n",
      " [  0 230 202  51 135]\n",
      " [  0 138 316 140 213]\n",
      " [  0 100 174 170 208]\n",
      " [  0  48  99  41 651]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.31041\tvalid_1's multi_logloss: 1.3801\n",
      "[200]\ttraining's multi_logloss: 1.20372\tvalid_1's multi_logloss: 1.33412\n",
      "[300]\ttraining's multi_logloss: 1.1205\tvalid_1's multi_logloss: 1.30801\n",
      "[400]\ttraining's multi_logloss: 1.05014\tvalid_1's multi_logloss: 1.29013\n",
      "[500]\ttraining's multi_logloss: 0.988091\tvalid_1's multi_logloss: 1.27832\n",
      "[600]\ttraining's multi_logloss: 0.932512\tvalid_1's multi_logloss: 1.27006\n",
      "[700]\ttraining's multi_logloss: 0.881693\tvalid_1's multi_logloss: 1.26371\n",
      "[800]\ttraining's multi_logloss: 0.835119\tvalid_1's multi_logloss: 1.25839\n",
      "[900]\ttraining's multi_logloss: 0.792176\tvalid_1's multi_logloss: 1.25496\n",
      "[1000]\ttraining's multi_logloss: 0.752176\tvalid_1's multi_logloss: 1.25261\n",
      "[1100]\ttraining's multi_logloss: 0.714729\tvalid_1's multi_logloss: 1.25091\n",
      "[1200]\ttraining's multi_logloss: 0.679856\tvalid_1's multi_logloss: 1.25023\n",
      "[1300]\ttraining's multi_logloss: 0.647373\tvalid_1's multi_logloss: 1.25011\n",
      "[1400]\ttraining's multi_logloss: 0.616676\tvalid_1's multi_logloss: 1.25019\n",
      "Early stopping, best iteration is:\n",
      "[1324]\ttraining's multi_logloss: 0.639825\tvalid_1's multi_logloss: 1.24995\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1160, 2: 787, 1: 618, 3: 424, 0: 8})\n",
      "CV split QWK score: 0.41298489948707695\n",
      "Confusion matrix:\n",
      " [[  6  20  19  12  25]\n",
      " [  2 261 173  61 121]\n",
      " [  0 177 312 111 207]\n",
      " [  0 101 179 193 178]\n",
      " [  0  59 104  47 629]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "QWK scores: [0.42965419232591184, 0.3967983731763258, 0.4254854877112828, 0.41192448303799256, 0.41298489948707695]\n",
      "Mean QWK score: 0.415369487147718\n",
      "QWK score sd: 0.01156569803510109\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 40,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 240,\n",
    "          'min_sum_hessian_in_leaf': 0.005,\n",
    "          'bagging_fraction': 0.5,\n",
    "          'bagging_frequency': 100,\n",
    "          'feature_fraction': 0.5,\n",
    "          'lambda_l2': 0.01,\n",
    "          'min_gain_to_split': 0.0,\n",
    "          'max_bin': 100,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }\n",
    "\n",
    "classification_model2_results = cv_model(X_train_reduced, y_train, 5, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model analysis and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least insofar as concerns the Kaggle competition public leaderboard, the initial models perform somewhat poorly. The multi-logloss results for each fold suggest the model is overfitting, but attempts to resolve by e.g. decreasing the `num_leaves` and `max_bin` hyperparameters did not consistently improve the QWK score within folds, nor the mean QWK score. Reducing the number of features also had minimal impact on the QWK score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual distribution of categories: Counter({4: 4197, 2: 4037, 3: 3259, 1: 3090, 0: 410})\n",
      "Predicted distribution of categories: Counter({4.0: 5901, 2.0: 4031, 1.0: 2904, 3.0: 2116, 0.0: 41})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Actual distribution of categories: {Counter(y_train)}\")\n",
    "print(f\"Predicted distribution of categories: {Counter(np.round(np.mean(classification_model2_results['lgb_preds'],axis=1)))}\")\n",
    "# For some reason they're are out of order. I have no idea why..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of hyperparameter values, the models made similar classification errors. In terms of classification label distributions (above), the final model still struggles to accurately predict 0s and has a clear tendency to overpredict 4s. The former is likely caused by a relative lack of training examples and few strong predictors of class 0 in the feature set as discussed in the EDA notebook.\n",
    "\n",
    "Below is the confusion matrix for all folds in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_average_confmatrix(classification_model2_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting patterns here (the exact values will vary a little):\n",
    "- Only 5.6% of actual 0s are accurately classified. Of those that are misclassified, 33% are wrongly considered category 4, with the almost all the rest split somewhat between 1, 2 and 4.\n",
    "- 37% of 1s are correctly classified. However, 30% are misclassified as 2s and a further 26% as 4s.\n",
    "- 28% of 3s are correct, with 30% wrong classified as 2s and 29% as 4s.\n",
    "\n",
    "This suggests that some form of redistributing the classifications might improve the overall accuracy (and, more importantly, QWK score) of the model. Luckily, some Kaggle users with more knowledge/experience than me have already gone down this route. What follows in the next section is an implementation of what appears to currently be the most popular solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM: regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section I fitted a LightGBM classification model to the training data. This did not perform as well as hoped, seemingly regardless of hyperparameter values, with an average overall QWK score of between about 0.399 and 0.400. An approach currently being experimented with on Kaggle for this particular competition (starting, I believe, in [this kernel](https://www.kaggle.com/abhishek/maybe-something-interesting-here) by Abhishek) is to fit a regression model to the data then bin the continuous predictions (0 to +inf) into the required categorical predictions (0 to 4). By adjusting the thresholds for each bin, the overall accuracy/QWK score of the model can be improved beyond what could be achieved by the earlier classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'Optimized Rounder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to the success of the binning of the continuous prediction values is the selection of optimal threshold values. In the aforementioned kernel, this is done by minimizing a loss function, in this case the (negative) QWK score.\n",
    "\n",
    "The `OptimizedRounder` has three parts:\n",
    "1. Initial coefficient (threshold) values are chosen\n",
    "2. The QWK loss function is minimized using the Nelder-Mead algorithm\n",
    "3. The optimized coefficient values are used to bin the validation/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    From https://www.kaggle.com/abhishek/maybe-something-interesting-here\n",
    "    I have added some comments for documentation/explanation\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = quadratic_weighted_kappa(y, X_p)\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
