{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Petfinder.my competition: modelling, part one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import feather\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = os.path.join(os.pardir, 'data', 'interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = feather.read_dataframe(os.path.join(INPUT_PATH, 'train.feather'))\n",
    "all_test = feather.read_dataframe(os.path.join(INPUT_PATH, 'test.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits the training data into training and validation data sets. The size of the validation data was calculated to match the size of the final unseen testing data relative to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_colnames = ['RescuerID', 'PetID', 'PrimaryLabel', 'SecondaryLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical data\n",
    "all_data = [all_train, all_test]\n",
    "\n",
    "for df in all_data:\n",
    "    for col in cat_colnames:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "        df[col] = df[col].cat.codes\n",
    "        df[col] = pd.Categorical(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Name', 'Description', 'AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_train.drop(drop_cols, axis=1)\n",
    "y_train = all_train['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_valid, y_train, y_valid = train_test_split(training_data, training_labels,\n",
    "#                                                      test_size=len(all_test) / len(all_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 346) (14993,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM: initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits a LightGBM classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition uses the quadratic weighted kappa for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kappa_metric(predictions, actuals):\n",
    "    \"\"\"\n",
    "    Competition scores are calculated with the quadratic weighted kappa.\n",
    "    The cohen_kappa_score from sklearn.metrics is identical\n",
    "    \"\"\"\n",
    "    return cohen_kappa_score(predictions, actuals, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix'):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    From https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in range(0, 5)],\n",
    "                      columns = [i for i in range(0, 5)])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 80,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 60,\n",
    "          'min_sum_hessian_in_leaf': 0.01,\n",
    "          'bagging_fraction': 0.75,\n",
    "          'bagging_frequency': 2,\n",
    "          'feature_fraction': 0.75,\n",
    "          'lambda_l2': 0.05,\n",
    "          'min_gain_to_split': 0.0,\n",
    "          'max_bin': 255,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(train_data, train_labels, valid_data, valid_labels,\n",
    "              model_params, scoring_metric, X_test=None):\n",
    "    \n",
    "    # Create training and validation lgb dataset objects\n",
    "    lgb_X_train = lgb.Dataset(data=train_data, label=train_labels,\n",
    "                              feature_name='auto', categorical_feature='auto',\n",
    "                              free_raw_data=False)\n",
    "    lgb_X_valid = lgb.Dataset(data=valid_data, label=valid_labels,\n",
    "                              feature_name='auto', categorical_feature='auto',\n",
    "                              free_raw_data=False)\n",
    "    \n",
    "    # Get parameters\n",
    "    params2 = model_params.copy()\n",
    "    num_iterations = params2.pop('num_iterations')\n",
    "    early_stopping = params2.pop('early_stopping_rounds')\n",
    "    verbose_eval = params2.pop('verbose_eval')\n",
    "    \n",
    "    # Train LightGBM model\n",
    "    print(\"Training the LightGBM model...\")\n",
    "    model = lgb.train(params2,\n",
    "                          lgb_X_train,\n",
    "                          num_boost_round=num_iterations,\n",
    "                          valid_sets=[lgb_X_train, lgb_X_valid],\n",
    "                          early_stopping_rounds=early_stopping,\n",
    "                          verbose_eval=verbose_eval)\n",
    "    \n",
    "    # Get model predictions on validation set\n",
    "    print(\"Fitting the model to the validation data...\")\n",
    "    y_probs = model.predict(valid_data, num_iteration=model.best_iteration,\n",
    "                           verbose_eval=verbose_eval) # Class probabilities from model\n",
    "    \n",
    "    \n",
    "    y_preds = np.apply_along_axis(np.argmax, 1, y_probs) # Get label value according to highest probability\n",
    "    qwk = scoring_metric(y_preds, valid_labels) # Compute kappa score\n",
    "    conf_matrix = confusion_matrix(valid_labels, y_preds)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Actual distribution of labels: {Counter(valid_labels)}\")\n",
    "    print(f\"Predicted distribution of labels: {Counter(y_preds)}\")\n",
    "    print(f\"CV split QWK score: {qwk}\")\n",
    "    print(\"Confusion matrix:\\n\", conf_matrix)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return y_probs, y_preds, qwk, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(X:pd.DataFrame, y:list, nsplits:int, params):\n",
    "    fold_counter = 1 #The current fold number\n",
    "    skf = StratifiedKFold(n_splits=nsplits, shuffle=True)\n",
    "    \n",
    "    lgb_preds = np.zeros((X.shape[0], nsplits))\n",
    "    lgb_pred_probs = []\n",
    "    lgb_confusion_matrices = []\n",
    "    lgb_qwk_scores = []\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        print(f\"Fold {fold_counter} / {nsplits}:\")\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        # Fit model\n",
    "        y_probs, y_preds, qwk, conf_matrix = lgb_model(X_train, y_train, X_valid, y_valid, params, kappa_metric)\n",
    "        \n",
    "        lgb_preds[valid_index] = y_preds.reshape(-1, 1)\n",
    "        lgb_pred_probs.append(y_probs)\n",
    "        lgb_qwk_scores.append(qwk)\n",
    "        lgb_confusion_matrices.append(conf_matrix)\n",
    "        \n",
    "        fold_counter += 1\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"QWK scores: {lgb_qwk_scores}\")\n",
    "    print(f\"Mean QWK score: {np.mean(lgb_qwk_scores)}\")\n",
    "    print(f\"QWK score sd: {np.std(lgb_qwk_scores)}\")\n",
    "    return lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.16233\tvalid_1's multi_logloss: 1.3511\n",
      "[200]\ttraining's multi_logloss: 0.961456\tvalid_1's multi_logloss: 1.30181\n",
      "[300]\ttraining's multi_logloss: 0.81081\tvalid_1's multi_logloss: 1.27727\n",
      "[400]\ttraining's multi_logloss: 0.691224\tvalid_1's multi_logloss: 1.2635\n",
      "[500]\ttraining's multi_logloss: 0.593743\tvalid_1's multi_logloss: 1.25729\n",
      "[600]\ttraining's multi_logloss: 0.512941\tvalid_1's multi_logloss: 1.25426\n",
      "[700]\ttraining's multi_logloss: 0.445001\tvalid_1's multi_logloss: 1.25348\n",
      "Early stopping, best iteration is:\n",
      "[666]\ttraining's multi_logloss: 0.466804\tvalid_1's multi_logloss: 1.25326\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1215, 2: 868, 1: 522, 3: 388, 0: 7})\n",
      "CV split QWK score: 0.4274781890782652\n",
      "Confusion matrix:\n",
      " [[  5  22  25   6  24]\n",
      " [  0 239 193  64 122]\n",
      " [  2 140 345 107 214]\n",
      " [  0  65 210 176 201]\n",
      " [  0  56  95  35 654]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.16187\tvalid_1's multi_logloss: 1.35312\n",
      "[200]\ttraining's multi_logloss: 0.961376\tvalid_1's multi_logloss: 1.30402\n",
      "[300]\ttraining's multi_logloss: 0.810672\tvalid_1's multi_logloss: 1.27908\n",
      "[400]\ttraining's multi_logloss: 0.690561\tvalid_1's multi_logloss: 1.2656\n",
      "[500]\ttraining's multi_logloss: 0.592595\tvalid_1's multi_logloss: 1.25909\n",
      "[600]\ttraining's multi_logloss: 0.511673\tvalid_1's multi_logloss: 1.25631\n",
      "[700]\ttraining's multi_logloss: 0.443745\tvalid_1's multi_logloss: 1.25683\n",
      "Early stopping, best iteration is:\n",
      "[657]\ttraining's multi_logloss: 0.47155\tvalid_1's multi_logloss: 1.25597\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1199, 2: 790, 1: 589, 3: 415, 0: 7})\n",
      "CV split QWK score: 0.3945191516054416\n",
      "Confusion matrix:\n",
      " [[  4  26  20   5  27]\n",
      " [  2 250 168  59 139]\n",
      " [  0 156 304 142 206]\n",
      " [  1 100 185 174 192]\n",
      " [  0  57 113  35 635]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.16039\tvalid_1's multi_logloss: 1.35522\n",
      "[200]\ttraining's multi_logloss: 0.959548\tvalid_1's multi_logloss: 1.31059\n",
      "[300]\ttraining's multi_logloss: 0.808662\tvalid_1's multi_logloss: 1.28803\n",
      "[400]\ttraining's multi_logloss: 0.688213\tvalid_1's multi_logloss: 1.27596\n",
      "[500]\ttraining's multi_logloss: 0.590691\tvalid_1's multi_logloss: 1.27005\n",
      "[600]\ttraining's multi_logloss: 0.509939\tvalid_1's multi_logloss: 1.26781\n",
      "[700]\ttraining's multi_logloss: 0.442416\tvalid_1's multi_logloss: 1.26836\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttraining's multi_logloss: 0.492608\tvalid_1's multi_logloss: 1.26745\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1297, 2: 825, 1: 499, 3: 371, 0: 6})\n",
      "CV split QWK score: 0.38318817417090734\n",
      "Confusion matrix:\n",
      " [[  5  18  24   4  31]\n",
      " [  1 197 218  38 164]\n",
      " [  0 146 314 114 233]\n",
      " [  0  92 181 175 204]\n",
      " [  0  46  88  40 665]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.15909\tvalid_1's multi_logloss: 1.35443\n",
      "[200]\ttraining's multi_logloss: 0.958047\tvalid_1's multi_logloss: 1.30723\n",
      "[300]\ttraining's multi_logloss: 0.806955\tvalid_1's multi_logloss: 1.28341\n",
      "[400]\ttraining's multi_logloss: 0.686785\tvalid_1's multi_logloss: 1.27111\n",
      "[500]\ttraining's multi_logloss: 0.589325\tvalid_1's multi_logloss: 1.26616\n",
      "[600]\ttraining's multi_logloss: 0.508308\tvalid_1's multi_logloss: 1.26526\n",
      "Early stopping, best iteration is:\n",
      "[567]\ttraining's multi_logloss: 0.5334\tvalid_1's multi_logloss: 1.26514\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1211, 2: 816, 1: 569, 3: 395, 0: 7})\n",
      "CV split QWK score: 0.39337312474117203\n",
      "Confusion matrix:\n",
      " [[  3  26  17   5  31]\n",
      " [  4 242 177  56 139]\n",
      " [  0 146 325 125 211]\n",
      " [  0  96 193 178 185]\n",
      " [  0  59 104  31 645]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.16131\tvalid_1's multi_logloss: 1.35804\n",
      "[200]\ttraining's multi_logloss: 0.960678\tvalid_1's multi_logloss: 1.30918\n",
      "[300]\ttraining's multi_logloss: 0.809636\tvalid_1's multi_logloss: 1.28398\n",
      "[400]\ttraining's multi_logloss: 0.689393\tvalid_1's multi_logloss: 1.26983\n",
      "[500]\ttraining's multi_logloss: 0.591485\tvalid_1's multi_logloss: 1.26291\n",
      "[600]\ttraining's multi_logloss: 0.510686\tvalid_1's multi_logloss: 1.26067\n",
      "[700]\ttraining's multi_logloss: 0.442867\tvalid_1's multi_logloss: 1.2606\n",
      "Early stopping, best iteration is:\n",
      "[640]\ttraining's multi_logloss: 0.482157\tvalid_1's multi_logloss: 1.26\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1254, 2: 813, 1: 565, 3: 358, 0: 7})\n",
      "CV split QWK score: 0.4034335620602214\n",
      "Confusion matrix:\n",
      " [[  6  22  18   6  30]\n",
      " [  0 254 172  51 141]\n",
      " [  0 144 323 107 233]\n",
      " [  1  99 197 163 191]\n",
      " [  0  46 103  31 659]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "Mean QWK score: 0.4003984403312016\n"
     ]
    }
   ],
   "source": [
    "lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices = cv_model(X_train, y_train, 5, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 / 5:\n",
      "Training the LightGBM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Envs/petfinder/lib/python3.6/site-packages/lightgbm/basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22375\tvalid_1's multi_logloss: 1.36018\n",
      "[200]\ttraining's multi_logloss: 1.06119\tvalid_1's multi_logloss: 1.31451\n",
      "[300]\ttraining's multi_logloss: 0.93395\tvalid_1's multi_logloss: 1.28991\n",
      "[400]\ttraining's multi_logloss: 0.827995\tvalid_1's multi_logloss: 1.27735\n",
      "[500]\ttraining's multi_logloss: 0.737889\tvalid_1's multi_logloss: 1.27035\n",
      "[600]\ttraining's multi_logloss: 0.660146\tvalid_1's multi_logloss: 1.26645\n",
      "[700]\ttraining's multi_logloss: 0.592492\tvalid_1's multi_logloss: 1.26467\n",
      "[800]\ttraining's multi_logloss: 0.53299\tvalid_1's multi_logloss: 1.26406\n",
      "Early stopping, best iteration is:\n",
      "[786]\ttraining's multi_logloss: 0.54088\tvalid_1's multi_logloss: 1.26405\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1245, 2: 753, 1: 587, 3: 408, 0: 7})\n",
      "CV split QWK score: 0.4024990004774419\n",
      "Confusion matrix:\n",
      " [[  4  30  16   5  27]\n",
      " [  1 235 191  44 147]\n",
      " [  2 166 287 127 226]\n",
      " [  0  97 179 181 195]\n",
      " [  0  59  80  51 650]]\n",
      "----------------------------------------\n",
      "Fold 2 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22366\tvalid_1's multi_logloss: 1.36106\n",
      "[200]\ttraining's multi_logloss: 1.06111\tvalid_1's multi_logloss: 1.31479\n",
      "[300]\ttraining's multi_logloss: 0.933985\tvalid_1's multi_logloss: 1.29167\n",
      "[400]\ttraining's multi_logloss: 0.828548\tvalid_1's multi_logloss: 1.2775\n",
      "[500]\ttraining's multi_logloss: 0.738585\tvalid_1's multi_logloss: 1.26887\n",
      "[600]\ttraining's multi_logloss: 0.661185\tvalid_1's multi_logloss: 1.26353\n",
      "[700]\ttraining's multi_logloss: 0.593835\tvalid_1's multi_logloss: 1.25995\n",
      "[800]\ttraining's multi_logloss: 0.534449\tvalid_1's multi_logloss: 1.25878\n",
      "[900]\ttraining's multi_logloss: 0.482206\tvalid_1's multi_logloss: 1.25875\n",
      "Early stopping, best iteration is:\n",
      "[849]\ttraining's multi_logloss: 0.508063\tvalid_1's multi_logloss: 1.25837\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 840, 2: 808, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1213, 2: 792, 1: 560, 3: 427, 0: 8})\n",
      "CV split QWK score: 0.40975212656764315\n",
      "Confusion matrix:\n",
      " [[  7  25  22   9  19]\n",
      " [  1 243 178  52 144]\n",
      " [  0 143 316 131 218]\n",
      " [  0  92 177 198 185]\n",
      " [  0  57  99  37 647]]\n",
      "----------------------------------------\n",
      "Fold 3 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22424\tvalid_1's multi_logloss: 1.36056\n",
      "[200]\ttraining's multi_logloss: 1.06172\tvalid_1's multi_logloss: 1.31831\n",
      "[300]\ttraining's multi_logloss: 0.934956\tvalid_1's multi_logloss: 1.29638\n",
      "[400]\ttraining's multi_logloss: 0.828963\tvalid_1's multi_logloss: 1.28271\n",
      "[500]\ttraining's multi_logloss: 0.73835\tvalid_1's multi_logloss: 1.27457\n",
      "[600]\ttraining's multi_logloss: 0.6604\tvalid_1's multi_logloss: 1.27036\n",
      "[700]\ttraining's multi_logloss: 0.592687\tvalid_1's multi_logloss: 1.26836\n",
      "[800]\ttraining's multi_logloss: 0.533251\tvalid_1's multi_logloss: 1.2686\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's multi_logloss: 0.57961\tvalid_1's multi_logloss: 1.26824\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1226, 2: 784, 1: 584, 3: 400, 0: 4})\n",
      "CV split QWK score: 0.3974747492929458\n",
      "Confusion matrix:\n",
      " [[  2  23  17   8  32]\n",
      " [  0 237 191  60 130]\n",
      " [  1 164 307 124 211]\n",
      " [  1  98 183 170 200]\n",
      " [  0  62  86  38 653]]\n",
      "----------------------------------------\n",
      "Fold 4 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22328\tvalid_1's multi_logloss: 1.36033\n",
      "[200]\ttraining's multi_logloss: 1.0601\tvalid_1's multi_logloss: 1.31503\n",
      "[300]\ttraining's multi_logloss: 0.932198\tvalid_1's multi_logloss: 1.29231\n",
      "[400]\ttraining's multi_logloss: 0.825532\tvalid_1's multi_logloss: 1.27913\n",
      "[500]\ttraining's multi_logloss: 0.735316\tvalid_1's multi_logloss: 1.27177\n",
      "[600]\ttraining's multi_logloss: 0.657524\tvalid_1's multi_logloss: 1.26854\n",
      "[700]\ttraining's multi_logloss: 0.589829\tvalid_1's multi_logloss: 1.2661\n",
      "[800]\ttraining's multi_logloss: 0.530507\tvalid_1's multi_logloss: 1.2667\n",
      "Early stopping, best iteration is:\n",
      "[712]\ttraining's multi_logloss: 0.582328\tvalid_1's multi_logloss: 1.26597\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 652, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1242, 2: 842, 1: 542, 3: 368, 0: 4})\n",
      "CV split QWK score: 0.3481097613606795\n",
      "Confusion matrix:\n",
      " [[  3  24  11   6  38]\n",
      " [  1 224 197  37 159]\n",
      " [  0 142 306 126 233]\n",
      " [  0  83 223 163 183]\n",
      " [  0  69 105  36 629]]\n",
      "----------------------------------------\n",
      "Fold 5 / 5:\n",
      "Training the LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 1.22506\tvalid_1's multi_logloss: 1.35485\n",
      "[200]\ttraining's multi_logloss: 1.06332\tvalid_1's multi_logloss: 1.30558\n",
      "[300]\ttraining's multi_logloss: 0.935973\tvalid_1's multi_logloss: 1.28054\n",
      "[400]\ttraining's multi_logloss: 0.829808\tvalid_1's multi_logloss: 1.26474\n",
      "[500]\ttraining's multi_logloss: 0.739445\tvalid_1's multi_logloss: 1.25499\n",
      "[600]\ttraining's multi_logloss: 0.661241\tvalid_1's multi_logloss: 1.24985\n",
      "[700]\ttraining's multi_logloss: 0.593593\tvalid_1's multi_logloss: 1.24735\n",
      "[800]\ttraining's multi_logloss: 0.534027\tvalid_1's multi_logloss: 1.24672\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's multi_logloss: 0.557571\tvalid_1's multi_logloss: 1.2462\n",
      "Fitting the model to the validation data...\n",
      "----------------------------------------\n",
      "Actual distribution of labels: Counter({4: 839, 2: 807, 3: 651, 1: 618, 0: 82})\n",
      "Predicted distribution of labels: Counter({4: 1174, 2: 808, 1: 566, 3: 439, 0: 10})\n",
      "CV split QWK score: 0.4309980053901693\n",
      "Confusion matrix:\n",
      " [[  9  23  25   6  19]\n",
      " [  1 246 193  69 109]\n",
      " [  0 153 302 138 214]\n",
      " [  0  80 192 182 197]\n",
      " [  0  64  96  44 635]]\n",
      "----------------------------------------\n",
      "========================================\n",
      "QWK scores: [0.4024990004774419, 0.40975212656764315, 0.3974747492929458, 0.3481097613606795, 0.4309980053901693]\n",
      "Mean QWK score: 0.3977667286177759\n",
      "QWK score sd: 0.027335916176314097\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'softmax',\n",
    "          'num_class': 5,\n",
    "          'boosting': 'gbdt',\n",
    "          'nthread': 4,\n",
    "          'num_iterations': 10000,\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 60,\n",
    "          'max_depth': -1,\n",
    "          'min_data_in_leaf': 120,\n",
    "          'min_sum_hessian_in_leaf': 0.01,\n",
    "          'bagging_fraction': 0.8,\n",
    "          'bagging_frequency': 2,\n",
    "          'feature_fraction': 0.8,\n",
    "          'lambda_l2': 0.05,\n",
    "          'min_gain_to_split': 0.0,\n",
    "          'max_bin': 255,\n",
    "          'early_stopping_rounds': 100,\n",
    "          'data_random_seed': 42,\n",
    "          'verbosity': -1,\n",
    "          'verbose_eval': 100\n",
    "         }\n",
    "\n",
    "lgb_pred_probs, lgb_preds, lgb_qwk_scores, lgb_confusion_matrices = cv_model(X_train, y_train, 5, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
